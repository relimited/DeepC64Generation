{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "#### Baselines Notbook\n",
    "\n",
    "This notebook goes over building a linear predictor for the spectral envelope of the next sample.  The model looks like this:\n",
    "\n",
    "*y*(*n*) = a~1~*y*(*n*-1)-a~2~*y*(*n*-2) ... a~*M*~*y*(*n*-*M*)+*e*(*n*)\n",
    "\n",
    "* *M* is the order of the linear predictor\n",
    "* a~*i*=1~^*M*^ is the prediction coeffients\n",
    "* *e*(*n*) ya basic error term\n",
    "\n",
    "Its worth noting that we only look at *M* samples in the past to predict our waveform.\n",
    "\n",
    "Most of the rote linear algebra to solve this equation (and DSP know-how) will be taken care of by audiolazy, a lazy python audio library that has the implementations we need.\n",
    "\n",
    "(The first part of this notebook goes over building the LPC predictor, the next part is the generator function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from audiolazy import lpc, Stream, WavStream, sHz, AudioIO\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# useful constants\n",
    "DATA_DIR = './20-test-dataset'\n",
    "ARCHIVE_NAME = \"20-test-dataset.npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the archive into memory\n",
    "song_data = np.load(ARCHIVE_NAME)\n",
    "print(song_data.shape)\n",
    "print(song_data[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hm, the numpy version has some PRETTY WILD numbers, lets see what loading directly from a wav source looks like\n",
    "# NOTE: code chunk left in for posterity, we're operating on numpy arrays.  The numbers turned out to be right.\n",
    "wav_files = os.listdir(DATA_DIR)\n",
    "test_wav = wav_files[0]\n",
    "str_data = WavStream(os.path.join(DATA_DIR, test_wav))\n",
    "str_data.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trying to plot the spectral envelope of order 3 (3 sample behind)\n",
    "# note: I had to blow out the type to avoid numeric overflow problems (which would probably lead to unstable solutions?)\n",
    "lpc_coeffs = lpc(song_data[1].astype('float64'), order=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lpc_coeffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# audiolazy has a plotting interface?\n",
    "fig1 = lpc_coeffs.plot(plt.figure())\n",
    "fig1.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, lets try to use the lpc coeffs as a filter to generate sound.\n",
    "Steps:\n",
    "* run the LPC as a filter over the input signal, get the residuals\n",
    "* divide the analysis filter into 1 (the equation we want is 1 / the good shit) to get a synthesis filter\n",
    "* play the residuals forward using the synthesis filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_filt = lpc_coeffs\n",
    "residual = list(analysis_filt(song_data[0].astype('float64')))\n",
    "synth_filt = 1 / analysis_filt\n",
    "\n",
    "# should be the frequency response, or ye normie audio graph.  \n",
    "# Lets see if we can chart it!\n",
    "synth_audio = synth_filt(residual).take(200)\n",
    "synth_timesteps = list(range(len(synth_audio)))\n",
    "\n",
    "plt.plot(synth_timesteps, synth_audio)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# be INTENSELY careful with this segment.  LPC reconstructed audio is at FULL VOLUME, likely due to the autocorr\n",
    "# relations and the sinewaves that make up chiptunes\n",
    "\n",
    "rate=44100 #standard audio rate\n",
    "s, Hz = sHz(rate)\n",
    "gen_audio = synth_filt(residual)\n",
    "with AudioIO(True) as player: # True means \"wait for all sounds to stop\"\n",
    "    clip = gen_audio.take(int(0.5 * s))\n",
    "    # DON'T BE WEARING HEADPHONES RIGHT NOW, YOU WILL DIE\n",
    "    # player.play(clip, rate=rate) COMMENTED OUT FOR SAFETY, UNCOMMENT AT YOUR OWN RISK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### packaging up LPC as a prediction generator\n",
    "\n",
    "The basic idea is:\n",
    "* infer the prediction coeffs on some set of data\n",
    "* generate audio for a current song (which may or may not be in the prediction dataset)\n",
    "* run the predictor forward to get a sample for each timestep\n",
    "* yeild each sample in turn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lpc_prediction_gen(order, pred_song, train_data=None, coeffs=None):\n",
    "    \"\"\" Generator to get lpc predictions for a current song\n",
    "    Parameters:\n",
    "    order: int\n",
    "        Number of coefficents to use for the LPC encoding\n",
    "    pred_song: numpy array, dtype something that can be coerced to 'float64'\n",
    "        The song to predict with, we'll use this as our data to get the next prediction.\n",
    "        If identical to the train_data, we're trying to reconstruct the current song\n",
    "    train_data: numpy array, dtype something that can be coerced to 'float64'\n",
    "        This is the training data to infer the LPC coefficents used for prediction\n",
    "        If identical to pred_song, we're trying to reconstruct the current song\n",
    "        If using multiple songs, they should be boundried with order samples of silence (usually a 0)\n",
    "    coeffs: an audiolazy lpc instance (the thing lpc returns in audiolazy)\n",
    "        Optional.  Pass this in instead of training data if we want to reuse a set of already calculated equations\n",
    "    \"\"\"\n",
    "    if not coeffs:\n",
    "        print(\"Building an LP spectral predictor with {:d} coefficents\".format(order))\n",
    "        analysis_filt = lpc(train_data.astype('float64'), order=order)\n",
    "        print(\"Filter built, calculating generative filter...\")\n",
    "        synth_filt = 1 / analysis_filt\n",
    "    if coeffs:\n",
    "        analysis_filt = coeffs\n",
    "        synth_filt = 1 / coeffs\n",
    "\n",
    "    print(\"Getting residuals for current song...\")\n",
    "    # ok, now lets get the residuals on the prediction song\n",
    "    residuals = list(analysis_filt(pred_song.astype('float64')))\n",
    "    \n",
    "    print(\"Ready to generate samples!\")\n",
    "    # now we can start to yield new audio batches off the current residuals FOREVER\n",
    "    while True:\n",
    "        sample_stream = synth_filt(residual)\n",
    "        while True:\n",
    "            try:  # this is bad, but I'm not sure how to get the length of an audio stream\n",
    "                yield sample_stream.take()\n",
    "            except:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lpc_gen = lpc_prediction_gen(3, song_data[0], train_data=song_data[1], coeffs=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(lpc_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check to make sure we loop around\n",
    "for i in range(song_data[0].shape[0]):\n",
    "    next(lpc_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(lpc_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "name": "LPC_Baseline.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
