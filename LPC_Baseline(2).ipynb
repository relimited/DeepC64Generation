{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "#### Baselines Notbook\n",
    "\n",
    "This notebook goes over building a linear predictor for the spectral envelope of the next sample.  The model looks like this:\n",
    "\n",
    "*y*(*n*) = a~1~*y*(*n*-1)-a~2~*y*(*n*-2) ... a~*M*~*y*(*n*-*M*)+*e*(*n*)\n",
    "\n",
    "* *M* is the order of the linear predictor\n",
    "* a~*i*=1~^*M*^ is the prediction coeffients\n",
    "* *e*(*n*) ya basic error term\n",
    "\n",
    "Its worth noting that we only look at *M* samples in the past to predict our waveform.\n",
    "\n",
    "Most of the rote linear algebra to solve this equation (and DSP know-how) will be taken care of by audiolazy, a lazy python audio library that has the implementations we need.\n",
    "\n",
    "(The first part of this notebook goes over building the LPC predictor, the next part is the generator function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from audiolazy import lpc, Stream, WavStream, sHz, AudioIO\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# useful constants\n",
    "DATA_DIR = \"./20-test-dataset\"\n",
    "ARCHIVE_NAME = \"20-test-dataset.npy\"\n",
    "LABELED_ARCHIVE_NAME = \"20-test-archive.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the archive into memory\n",
    "song_data = np.load(ARCHIVE_NAME)\n",
    "print(song_data.shape)\n",
    "print(song_data[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the pickled archive into memory\n",
    "labeled_song_data = {}\n",
    "with open(LABELED_ARCHIVE_NAME, 'rb') as f:\n",
    "    labeled_song_data = pickle.load(f)\n",
    "print([key for key in labeled_song_data.keys()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hm, the numpy version has some PRETTY WILD numbers, lets see what loading directly from a wav source looks like\n",
    "# NOTE: code chunk left in for posterity, we're operating on numpy arrays.  The numbers turned out to be right.\n",
    "wav_files = os.listdir(DATA_DIR)\n",
    "test_wav = wav_files[0]\n",
    "str_data = WavStream(os.path.join(DATA_DIR, test_wav))\n",
    "str_data.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trying to plot the spectral envelope of order 10 (use the 10 previous samples)\n",
    "# note: I had to blow out the type to avoid numeric overflow problems (which would probably lead to unstable solutions?)\n",
    "lpc_coeffs = lpc(song_data[10].astype('float64'), order=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lpc_coeffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets check out some signal response curves\n",
    "fig1 = lpc_coeffs.plot(plt.figure())\n",
    "fig1.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, lets try to use the lpc coeffs as a filter to generate sound.\n",
    "Steps:\n",
    "* run the LPC as a filter over the input signal, get the residuals\n",
    "* divide the analysis filter into 1 (the equation we want is 1 / the good shit) to get a synthesis filter\n",
    "* play the residuals forward using the synthesis filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_filt = lpc_coeffs\n",
    "residual = list(analysis_filt(song_data[9].astype('float64')))\n",
    "synth_filt = 1 / analysis_filt\n",
    "\n",
    "# should be the frequency response, or ye normie audio graph.  \n",
    "# Lets see if we can chart it!\n",
    "synth_audio = synth_filt(residual).take(1000) #the first 1k samples isn't even a ms of audio\n",
    "synth_timesteps = list(range(len(synth_audio)))\n",
    "\n",
    "# convert the 16-bit audio to a signal from -1 to 1 (ye normie way of looking at audio)\n",
    "plot_audio = [sample / 32768.0 for sample in synth_audio] \n",
    "plt.plot(synth_timesteps, plot_audio)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# that looks painful to listen to.  Lets get an accuracy metric comparing the first 200 samples\n",
    "true_data = Stream(song_data[9].astype('float64')).take(1000)\n",
    "mse = mean_squared_error(synth_audio, true_data)\n",
    "print(\"MSE: {}\".format(mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# be INTENSELY careful with this segment.  LPC reconstructed audio is at FULL VOLUME\n",
    "# can't tell if this is a feature or a bug.\n",
    "\n",
    "rate=44100 #standard audio rate\n",
    "s, Hz = sHz(rate)\n",
    "gen_audio = synth_filt(residual)\n",
    "with AudioIO(True) as player: # True means \"wait for all sounds to stop\"\n",
    "    clip = gen_audio.take(int(10 * s))\n",
    "    # DON'T BE WEARING HEADPHONES RIGHT NOW, YOU WILL DIE\n",
    "    player.play(clip, rate=rate) #COMMENTED OUT FOR SAFETY, UNCOMMENT AT YOUR OWN RISK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell to play a song streight rather than reconstructing\n",
    "rate=44100 #standard audio rate\n",
    "s, Hz = sHz(rate)\n",
    "audio = Stream(song_data[9])\n",
    "with AudioIO(True) as player:\n",
    "    clip = audio.take(int(5 * s))\n",
    "    player.play(clip, rate=rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### USING THE .pkl ARCHIVE\n",
    "\n",
    "We'd like some more control over which songs we're using to infer the coeffs on the linear function for, and which songs we're using those coeffs to play back.\n",
    "THIS IS THAT THING."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# complete the loop using the pickle file to have better control on which files are being used for for LPC stuff\n",
    "train_song = '<?> - Soccer Boss (song 1).wav'\n",
    "gen_song = 'Henke <?> - Space Game (song 1).wav'\n",
    "analysis_filt = lpc(labeled_song_data[train_song]['data'].astype('float64'), order=10)\n",
    "fig1 = analysis_filt.plot(plt.figure())\n",
    "fig1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residual = list(labeled_song_data[gen_song]['data'].astype('float64'))\n",
    "synth_filt = 1 / analysis_filt\n",
    "\n",
    "gen_audio = synth_filt(residual)\n",
    "with AudioIO(True) as player: # True means \"wait for all sounds to stop\"\n",
    "    clip = gen_audio.take(int(10 * s))\n",
    "    # DON'T BE WEARING HEADPHONES RIGHT NOW, YOU WILL DIE\n",
    "    player.play(clip, rate=rate) #COMMENTED OUT FOR SAFETY, UNCOMMENT AT YOUR OWN RISK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### packaging up LPC as a prediction generator\n",
    "\n",
    "The basic idea is:\n",
    "* infer the prediction coeffs on some set of data\n",
    "* generate audio for a current song (which may or may not be in the prediction dataset)\n",
    "* run the predictor forward to get a sample for each timestep\n",
    "* yeild each sample in turn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lpc_prediction_gen(order, pred_song, train_data=None, coeffs=None):\n",
    "    \"\"\" Generator to get lpc predictions for a current song\n",
    "    Parameters:\n",
    "    order: int\n",
    "        Number of coefficents to use for the LPC encoding\n",
    "    pred_song: numpy array, dtype something that can be coerced to 'float64'\n",
    "        The song to predict with, we'll use this as our data to get the next prediction.\n",
    "        If identical to the train_data, we're trying to reconstruct the current song\n",
    "    train_data: numpy array, dtype something that can be coerced to 'float64'\n",
    "        This is the training data to infer the LPC coefficents used for prediction\n",
    "        If identical to pred_song, we're trying to reconstruct the current song\n",
    "        If using multiple songs, they should be boundried with order samples of silence (usually a 0)\n",
    "    coeffs: an audiolazy lpc instance (the thing lpc returns in audiolazy)\n",
    "        Optional.  Pass this in instead of training data if we want to reuse a set of already calculated equations\n",
    "    \"\"\"\n",
    "    if not coeffs:\n",
    "        print(\"Building an LP spectral predictor with {:d} coefficents\".format(order))\n",
    "        analysis_filt = lpc(train_data.astype('float64'), order=order)\n",
    "        print(\"Filter built, calculating generative filter...\")\n",
    "        synth_filt = 1 / analysis_filt\n",
    "    if coeffs:\n",
    "        analysis_filt = coeffs\n",
    "        synth_filt = 1 / coeffs\n",
    "\n",
    "    print(\"Getting residuals for current song...\")\n",
    "    # ok, now lets get the residuals on the prediction song\n",
    "    residuals = list(analysis_filt(pred_song.astype('float64')))\n",
    "    \n",
    "    print(\"Ready to generate samples!\")\n",
    "    # now we can start to yield new audio batches off the current residuals FOREVER\n",
    "    while True:\n",
    "        sample_stream = synth_filt(residual)\n",
    "        while True:\n",
    "            try:  # this is bad, but I'm not sure how to get the length of an audio stream\n",
    "                yield sample_stream.take()\n",
    "            except:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lpc_gen = lpc_prediction_gen(3, song_data[0], train_data=song_data[1], coeffs=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(lpc_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check to make sure we loop around\n",
    "for i in range(song_data[0].shape[0]):\n",
    "    next(lpc_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(lpc_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "name": "LPC_Baseline.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
